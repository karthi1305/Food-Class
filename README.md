This project leverages convolutional neural networks (CNNs) to classify food items from images, addressing the growing need for effective food monitoring in health-related contexts. By utilizing 2D convolution layers and Max-Pooling functions, the CNN model accurately extracts and processes features from image pixels. Evaluated on the FOOD-101 dataset, the model achieves an impressive accuracy of 86.97%, demonstrating its potential for automated dietary monitoring and analysis.
